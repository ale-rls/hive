{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Доступные ресурсы - Russian DALL-E",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAw2262ARz1Y"
      },
      "source": [
        "Доступные ресурсы -Russian DALL-E :)\n",
        "\n",
        "By russian company [Sber](https://github.com/sberbank-ai/ru-dalle).\n",
        "\n",
        "With added translation step. You should be able to input any language.\n",
        "\n",
        "![Russian Roulette](https://pbs.twimg.com/media/FDNZJeUXsAkmBgg?format=jpg&name=360x360)\n",
        "\n",
        "*Example: Russian Roulette*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "DRR-MpnHRvZ-"
      },
      "source": [
        "\n",
        "# Text Prompt. Can be any language.\n",
        "text_input = 'russian roulette'  #@param {type: \"string\"}´\n",
        "\n",
        "output_path = \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXHbpMh1QlWd",
        "cellView": "form"
      },
      "source": [
        "#@title Доступные ресурсы\n",
        "import multiprocessing\n",
        "import torch\n",
        "from psutil import virtual_memory\n",
        "\n",
        "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
        "\n",
        "print('CPU:', multiprocessing.cpu_count())\n",
        "print('RAM GB:', ram_gb)\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device.type)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UJXhzngQOVT"
      },
      "source": [
        "!pip install translators --upgrade\n",
        "import translators as ts\n",
        "\n",
        "def to_russian(text):\n",
        "  return ts.google(text, to_language=\"ru\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my3y3ORmQpYU"
      },
      "source": [
        "!pip install rudalle==0.0.1rc4 > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBMm0cVRV-E"
      },
      "source": [
        "from rudalle.pipelines import generate_images, show, super_resolution, cherry_pick_by_clip\n",
        "from rudalle import get_rudalle_model, get_tokenizer, get_vae, get_realesrgan, get_ruclip\n",
        "from rudalle.utils import seed_everything"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwzWV3I7SB3g"
      },
      "source": [
        "device = 'cuda'\n",
        "dalle = get_rudalle_model('Malevich', pretrained=True, fp16=True, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFpu82HiSB7u"
      },
      "source": [
        "realesrgan = get_realesrgan('x4', device=device)\n",
        "tokenizer = get_tokenizer()\n",
        "vae = get_vae().to(device)\n",
        "ruclip, ruclip_processor = get_ruclip('ruclip-vit-base-patch32-v5')\n",
        "ruclip = ruclip.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x02MYpdYZ-5"
      },
      "source": [
        "## generation by ruDALLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdOYJvwZSB-D"
      },
      "source": [
        "text = to_russian(text_input)\n",
        "pil_images = []\n",
        "scores = []\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "for top_k, top_p, images_num in [\n",
        "    (1024, 0.98, 1),\n",
        "]:\n",
        "    _pil_images, _scores = generate_images(text, tokenizer, dalle, vae, top_k=top_k, images_num=images_num, top_p=top_p)\n",
        "    pil_images += _pil_images\n",
        "    scores += _scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4sY-ZCSCA7"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVjTQ3JPYilA"
      },
      "source": [
        "### auto-cherry-pick by ruCLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZI2y4KEYma5"
      },
      "source": [
        "## super resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-sfSSBzQpar"
      },
      "source": [
        "sr_images = super_resolution(pil_images, realesrgan)\n",
        "for image in sr_images:\n",
        "  image.save(f\"{output_path}/output.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}