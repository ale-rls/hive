{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "DALL·E mini (Text-to-Image)",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook illustrates [DALL·E mini](https://github.com/borisdayma/dalle-mini) inference pipeline.\n",
        "\n",
        "For more understanding of the model, refer to [the report](https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA).\n",
        "\n",
        "<img src=\"https://github.com/borisdayma/dalle-mini/blob/main/img/logo.png?raw=true\" width=\"100\">"
      ],
      "metadata": {
        "id": "118UKH5bWCGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Text Prompt\n",
        "text_input = 'robot friend by Giuseppe Arcimboldo'  #@param {type: \"string\"}\n",
        "\n",
        "# Perform 4x neural super-resolution (from 256x256px to 1024x124)\n",
        "super_resolution = True   #@param {type: \"boolean\"}\n",
        "\n",
        "output_path = '/content/output'"
      ],
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "d7rQxnvpZ06N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "dS8LbaonYm3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /contnet\n",
        "!pip install -q transformers flax\n",
        "!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git  # VQGAN model in JAX\n",
        "!git clone https://github.com/borisdayma/dalle-mini  # Model files\n",
        "%cd /content/dalle-mini/"
      ],
      "outputs": [],
      "metadata": {
        "id": "uzjAM2GBYpZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate encoded images\n",
        "\n",
        "We generate prediction samples from a text prompt using `flax-community/dalle-mini` model."
      ],
      "metadata": {
        "id": "phQ9bhjRkgAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from dalle_mini.model import CustomFlaxBartForConditionalGeneration\n",
        "from transformers import BartTokenizer\n",
        "import jax\n",
        "import random\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "outputs": [],
      "metadata": {
        "id": "yyT4tk5EbsdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# make sure we use compatible versions\n",
        "DALLE_REPO = 'flax-community/dalle-mini'\n",
        "DALLE_COMMIT_ID = '4d34126d0df8bc4a692ae933e3b902a1fa8b6114'"
      ],
      "outputs": [],
      "metadata": {
        "id": "pHv8hKFpcF7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# set up tokenizer and model\n",
        "tokenizer = BartTokenizer.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)\n",
        "model = CustomFlaxBartForConditionalGeneration.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)"
      ],
      "outputs": [],
      "metadata": {
        "id": "k82AaQlGcq0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# set a prompt\n",
        "prompt = text_input"
      ],
      "outputs": [],
      "metadata": {
        "id": "IBFSuYbSgIf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# tokenize the prompt\n",
        "tokenized_prompt = tokenizer(prompt, return_tensors='jax', padding='max_length', truncation=True, max_length=128)\n",
        "tokenized_prompt"
      ],
      "outputs": [],
      "metadata": {
        "id": "a0MRpCVyhZXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "* `0`: BOS, special token representing the beginning of a sequence\n",
        "* `2`: EOS, special token representing the end of a sequence\n",
        "* `1`: special token representing the padding of a sequence when requesting a specific length"
      ],
      "metadata": {
        "id": "_Y5dqFj7prMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "n_predictions = 8\n",
        "\n",
        "# create random keys\n",
        "seed = random.randint(0, 2**32-1)\n",
        "key = jax.random.PRNGKey(seed)\n",
        "subkeys = jax.random.split(key, num=n_predictions)\n",
        "subkeys"
      ],
      "outputs": [],
      "metadata": {
        "id": "MmfyDOrm-9hc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# generate sample predictions\n",
        "encoded_images = [model.generate(**tokenized_prompt, do_sample=True, num_beams=1, prng_key=subkey) for subkey in tqdm(subkeys)]\n",
        "encoded_images[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "_Xcf-BuCivEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first token (`16384`) is a special token representing the start of a sequence in the decoder (not part of the image codebook)."
      ],
      "metadata": {
        "id": "K3m2lxNOrQWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# remove first token (BOS)\n",
        "encoded_images = [img.sequences[..., 1:] for img in encoded_images]\n",
        "encoded_images[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "OIOjC-KEq5NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated images are now represented by 256 tokens."
      ],
      "metadata": {
        "id": "037WuNLXsCoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "encoded_images[0].shape"
      ],
      "outputs": [],
      "metadata": {
        "id": "U5KQfjilqvbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decode images\n",
        "\n",
        "The generated images need to be decoded with `flax-community/vqgan_f16_16384`."
      ],
      "metadata": {
        "id": "HDiVxh1wfrJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "outputs": [],
      "metadata": {
        "id": "yAmCIun8ftiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# make sure we use compatible versions\n",
        "VQGAN_REPO = 'flax-community/vqgan_f16_16384'\n",
        "VQGAN_COMMIT_ID = '90cc46addd2dd8f5be21586a9a23e1b95aa506a9'"
      ],
      "outputs": [],
      "metadata": {
        "id": "yzJyQhk9fvT2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# set up VQGAN\n",
        "vqgan = VQModel.from_pretrained(VQGAN_REPO, revision=VQGAN_COMMIT_ID)"
      ],
      "outputs": [],
      "metadata": {
        "id": "k9LrXhvJcx6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# decode images\n",
        "decoded_images = [vqgan.decode_code(encoded_image) for encoded_image in tqdm(encoded_images)]\n",
        "decoded_images[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "1hXb-F2bbMxK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# normalize images\n",
        "clipped_images = [img.squeeze().clip(0., 1.) for img in decoded_images]"
      ],
      "outputs": [],
      "metadata": {
        "id": "kqQM16K9L7HA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# convert to image\n",
        "images = [Image.fromarray(np.asarray(img * 255, dtype=np.uint8)) for img in clipped_images]"
      ],
      "outputs": [],
      "metadata": {
        "id": "isW9m1B9CH1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "del model\n",
        "del vqgan\n",
        "import gc\n",
        "gc.collect()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Upscale images/video frames\n",
        "\n",
        "\n",
        "loaded_upscale_model = False\n",
        "\n",
        "def upscale(filepath):\n",
        "  if not super_resolution:\n",
        "    return\n",
        "  global loaded_upscale_model\n",
        "  if not loaded_upscale_model:\n",
        "    # Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "    %cd /content/Real-ESRGAN\n",
        "    # Set up the environment\n",
        "    !pip install basicsr\n",
        "    !pip install facexlib\n",
        "    !pip install gfpgan\n",
        "    !pip install -r requirements.txt\n",
        "    !python setup.py develop\n",
        "    # Download the pre-trained model\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "    %cd -\n",
        "    loaded_upscale_model = True \n",
        "  \n",
        "  %cd /content/Real-ESRGAN\n",
        "  !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input $filepath --netscale 4 --outscale 3.5 --half --output $output_path\n",
        "  filepath_out = filepath.replace(\".jpg\",\"_out.jpg\")\n",
        "  !mv -v $filepath_out $filepath\n",
        "  %cd -"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mkdir -p $output_path\n",
        "# display an image\n",
        "for idx in range(len(images)):\n",
        "    #display(images[idx])\n",
        "    idx_str = '{:05}'.format(idx)\n",
        "    save_path = f\"{output_path}/image_{idx}.png\"\n",
        "    images[idx].save(save_path)\n",
        "    print(\"saved image to \", save_path)\n",
        "    upscale(save_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vPISO6sE-cI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "out_file=output_path+\"/video.mp4\"\n",
        "\n",
        "!ffmpeg -r 0.5 -i $output_path/%*.png -y -c:v libx264 -filter:v fps=fps=20 /tmp/vid_no_audio.mp4\n",
        "!ffmpeg -i /tmp/vid_no_audio.mp4 -f lavfi -i anullsrc -c:v copy -c:a aac -shortest -y \"$out_file\"\n",
        "\n",
        "print(\"Written\", out_file)\n",
        "!sleep 2\n",
        "!rm -r /tmp/ffmpeg\n",
        "!sleep 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "ew0cQYCGdKQU"
      }
    }
  ]
}