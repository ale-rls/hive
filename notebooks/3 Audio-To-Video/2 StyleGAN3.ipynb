{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHzltei9Ue7I"
      },
      "source": [
        "StyleGAN3 Music Video\n",
        "\n",
        "This Colab is to try out **StyleGAN3** (aka Alias-Free GAN) released in [this repo](https://github.com/NVlabs/stylegan3) by NVidia. Colab produced by [crimeacs](https://twitter.com/EarthML1). \n",
        "\n",
        "**[UPD 17.10.2021]** Added Music Video Generation\n",
        "\n",
        "[UPD 14.10.2021] Added Cosplay Faces trained by [@l4rz](https://twitter.com/l4rz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYj_p60AG6L_"
      },
      "outputs": [],
      "source": [
        "# StyleGAN model. afhq is animal faces. ffhq flickr faces and metfaces painted faces. Cosplay is anime style\n",
        "model = \"stylegan2-cosplay-faces-512x512-px\" #@param [\"stylegan2-cosplay-faces-512x512-px\", \"stylegan3-r-afhqv2-512x512.pkl\", \"stylegan3-r-ffhq-1024x1024.pkl\", \"stylegan3-r-ffhqu-1024x1024.pkl\",\"stylegan3-r-ffhqu-256x256.pkl\",\"stylegan3-r-metfaces-1024x1024.pkl\",\"stylegan3-r-metfacesu-1024x1024.pkl\",\"stylegan3-t-afhqv2-512x512.pkl\",\"stylegan3-t-ffhq-1024x1024.pkl\",\"stylegan3-t-ffhqu-1024x1024.pkl\",\"stylegan3-t-ffhqu-256x256.pkl\",\"stylegan3-t-metfaces-1024x1024.pkl\",\"stylegan3-t-metfacesu-1024x1024.pkl\"]\n",
        "\n",
        "# Input audio file (wav or mp3)\n",
        "audio_file = '' #@param {type: \"string\"}\n",
        "\n",
        "# Random seed. Each seed generates a unique image\n",
        "seed =  100500 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown How variable should the video be? (lower values - less variable)\n",
        "truncation_psi = 0.8 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Proportion between changing single image vs random images (just try it)\n",
        "single_image_vs_random =  0.9 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Cut audio to N seconds\n",
        "cut_len = -1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown How many frames to use for interpolation?\n",
        "interp_frames =  5 #@param {type:\"number\"}\n",
        "\n",
        "output_path = \"/content\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d99HsTjTQRzg"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "%cd stylegan3\n",
        "!wget -N -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local jupyter\n",
        "!python -m ipykernel install --name \"py38\" --user\n",
        "!pip install click -q\n",
        "!pip install numpy -q\n",
        "!pip install pillow -q\n",
        "!pip install torch -q\n",
        "!pip install scipy -q\n",
        "!pip install Ninja -q\n",
        "!pip install imageio -q\n",
        "!pip install imageio-ffmpeg -q\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "zFWf0Wi1_4P_",
        "outputId": "50e4ac89-d5fc-47a7-a892-47433ebb31b8"
      },
      "outputs": [],
      "source": [
        "#@title # Generate ðŸŽµ music video\n",
        "#@markdown ##**Choose your settings**\n",
        "from IPython.display import clear_output\n",
        "%cd /content/stylegan3\n",
        "\n",
        "import requests\n",
        "import pickle\n",
        "import torch \n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import time\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def fetch_model(url_or_path):\n",
        "    basename = os.path.basename(url_or_path)\n",
        "    if os.path.exists(basename):\n",
        "        return basename\n",
        "    else:\n",
        "        !wget -c '{url_or_path}'\n",
        "        return basename\n",
        "\n",
        "baselink ='https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/'\n",
        "\n",
        "if model == \"stylegan2-cosplay-faces-512x512-px\":\n",
        "    baselink = 'https://l4rz.net/'\n",
        "    model = 'cosplayface-snapshot-004000-18160-FID367.pkl'\n",
        "\n",
        "network_url = baselink + model\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "with open(fetch_model(network_url), 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "\n",
        "\n",
        "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "#!wget {audio_link} -O audio.mp3\n",
        "if audio_file.endswith('.mpeg'):\n",
        "    !mv $audio_file audio.mp3\n",
        "    audio_file = 'audio.mp3'\n",
        "    \n",
        "arr, fr = librosa.load(audio_file)\n",
        "if if cut_len == -1:\n",
        "  cut_len = len(arr) // fr\n",
        "else:\n",
        "    arr = arr[:fr*cut_len]\n",
        "\n",
        "wavfile.write('audio.wav', fr, arr)\n",
        "\n",
        "stft = torch.stft(torch.tensor(arr), \n",
        "           G.mapping.z_dim*2-1,  \n",
        "           center=False, \n",
        "           pad_mode='reflect', \n",
        "           normalized=True, \n",
        "           onesided=True, \n",
        "           return_complex=True)\n",
        "\n",
        "stft = torch.log(stft.abs())[:,::10]\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#FRAMES\n",
        "import time\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "zq = []\n",
        "with torch.no_grad():\n",
        "    timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "    rand_z = torch.randn(stft.size(-1), G.mapping.z_dim).to(device)\n",
        "    q = (G.mapping(rand_z, None, truncation_psi=truncation_psi))\n",
        "\n",
        "    for i in range(stft.size(-1)):\n",
        "        frame = stft[:,i].T.to(device)\n",
        "        z = torch.mean(G.mapping(frame.unsqueeze(0), None, truncation_psi=truncation_psi), dim=0)\n",
        "        zq.append(z.unsqueeze(0)*single_image_vs_random + q[i]*(1-single_image_vs_random))\n",
        "\n",
        "    count = 0\n",
        "    for k in tqdm(range(len(zq)-1)):\n",
        "        i_val = torch.linspace(0,1,interp_frames).to(device)\n",
        "        for interpolation in tqdm(i_val, leave=False):\n",
        "            interp = torch.lerp(zq[k], zq[k+1], interpolation)\n",
        "            images = G.synthesis(interp)\n",
        "            images = ((images + 1)/2).clamp(0,1)\n",
        "            pil_image = TF.to_pil_image(images[0].cpu())\n",
        "            os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "            pil_image.save(f'samples/{timestring}/{count:04}.png')\n",
        "            count+=1\n",
        "\n",
        "\n",
        "#VIDEO\n",
        "from IPython import display\n",
        "from base64 import b64encode\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "fps = count/cut_len\n",
        "\n",
        "frames = []\n",
        "# tqdm.write('Generating video...')\n",
        "for i in sorted(os.listdir(f'samples/{timestring}')): #\n",
        "    frames.append(Image.open(f\"samples/{timestring}/{i}\"))\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "    im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "p.wait()\n",
        "\n",
        "!ffmpeg -y -i video.mp4 -i audio.wav -map 0 -map 1:a -c:v copy -shortest video_audio.mp4\n",
        "!cp -v video_audio.mp4 $output_path\n",
        "clear_output()\n",
        "# mp4 = open('video.mp4','rb').read()\n",
        "#mp4 = open('video_audio.mp4','rb').read()\n",
        "#data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "#display.HTML(\"\"\"\n",
        "#<video width=400 controls>\n",
        "#      <source src=\"%s\" type=\"video/mp4\">\n",
        "#</video>\n",
        "#\"\"\" % data_url)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Audio-To-Video StyelGAN3",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
