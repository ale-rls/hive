{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed Forward VQGAN CLIP - Using a pretrained model .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/hive/blob/notebook-esrgan/Feed_Forward_VQGAN_CLIP_Using_a_pretrained_model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHN09TAisnpy"
      },
      "source": [
        "# Feed Forward VQGAN_CLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BIfsw25sk18"
      },
      "source": [
        "\n",
        "Feed forward VQGAN-CLIP model, where the goal is to eliminate the need for optimizing the latent space of VQGAN for each input prompt. This is done by training a model that takes as input a text prompt, and returns as an output the VQGAN latent space, which is then transformed into an RGB image. The model is trained on a dataset of text prompts and can be used on unseen text prompts. The loss function is minimizing the distance between the CLIP generated image features and the CLIP input text features. Additionally, a diversity loss can be used to make increase the diversity of the generated images given the same prompt.\n",
        "\n",
        "This notebooks shows how to use a pre-trained model for generating images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVOQrr6OSijT"
      },
      "source": [
        "super_resolution = True\n",
        "output_path = \"/content/output\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAJf6UVYS3Mz"
      },
      "source": [
        "!mkdir -p $output_path"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2LreFUFSkl9"
      },
      "source": [
        "#@title Upscale images/video frames\n",
        "\n",
        "loaded_upscale_model = False\n",
        "\n",
        "def upscale(filepath):\n",
        "  if not super_resolution:\n",
        "    return\n",
        "  global loaded_upscale_model\n",
        "  if not loaded_upscale_model:\n",
        "    # Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN.git /content\n",
        "    %cd /content/Real-ESRGAN\n",
        "    # Set up the environment\n",
        "    !pip install basicsr\n",
        "    !pip install facexlib\n",
        "    !pip install gfpgan\n",
        "    !pip install -r requirements.txt\n",
        "    !python setup.py develop\n",
        "    # Download the pre-trained model\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P experiments/pretrained_models\n",
        "    %cd -\n",
        "    loaded_upscale_model = True \n",
        "  \n",
        "  %cd /content/Real-ESRGAN\n",
        "  !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus_anime_6B.pth --input $filepath --netscale 4 --outscale 2 --half --output $output_path\n",
        "  filepath_out = filepath.replace(\".jpg\",\"_out.jpg\")\n",
        "  !mv -v $filepath_out $filepath\n",
        "  %cd -"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eto369VFWSMg",
        "outputId": "b8b9d553-f698-4410-f676-6a328e7527d2"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/mehdidc/feed_forward_vqgan_clip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'feed_forward_vqgan_clip' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsAT4IfWWZig",
        "outputId": "2ae6a658-afa9-4f92-c633-13156f0f03f1"
      },
      "source": [
        "cd feed_forward_vqgan_clip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feed_forward_vqgan_clip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNPGieSMWrex",
        "outputId": "c27fb197-53d4-4c29-e15e-90c0404d2af8"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: clize in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.3.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2021.8.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.5.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.19.5)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: taming-transformers-rom1504 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.9.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.10.0+cu102)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 1)) (4.62.2)\n",
            "Requirement already satisfied: od in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (1.0)\n",
            "Requirement already satisfied: sigtools>=2.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (2.0.3)\n",
            "Requirement already satisfied: attrs<22,>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (21.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 16)) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r requirements.txt (line 9)) (5.4.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r requirements.txt (line 9)) (4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (0.18.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (21.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (0.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.40.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (2021.5.30)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec->-r requirements.txt (line 4)) (3.7.4.post0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 15)) (4.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning->-r requirements.txt (line 12)) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 15)) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (5.1.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 15)) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOXgso54Wi6A",
        "outputId": "a1aba138-959f-4c89-dea0-e5af764a37a2"
      },
      "source": [
        "!sudo apt install aria2\n",
        "from pathlib import Path\n",
        "if not Path(\"vqgan_imagenet_f16_16384.yaml\").exists():\n",
        "    !aria2c -x 5 --auto-file-renaming=false 'https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/vqgan_imagenet_f16_16384.yaml' -o vqgan_imagenet_f16_16384.yaml\n",
        "    !aria2c -x 5 --auto-file-renaming=false 'https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/vqgan_imagenet_f16_16384.ckpt' -o vqgan_imagenet_f16_16384.ckpt\n",
        "\n",
        "\n",
        "if not Path(\"cc12m_32x1024.th\").exists():\n",
        "    !aria2c -x 5 --auto-file-renaming=false 'https://github.com/mehdidc/feed_forward_vqgan_clip/releases/download/0.1/cc12m_32x1024.th' -o cc12m_32x1024.th\n",
        "#check available models at https://github.com/mehdidc/feed_forward_vqgan_clip\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aria2 is already the newest version (1.33.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYS1xi4ks5as"
      },
      "source": [
        "# Load model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKlH2a90X2vs",
        "outputId": "2d96b6be-72f5-4029-8552-2afd10208f04"
      },
      "source": [
        "from IPython.display import Image\n",
        "import torch\n",
        "import clip\n",
        "from main import load_vqgan_model, CLIP_DIM, clamp_with_grad, synth\n",
        "import torchvision\n",
        "\n",
        "model_path = \"cc12m_32x1024.th\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "net = torch.load(model_path, map_location=\"cpu\").to(device)\n",
        "config = net.config\n",
        "vqgan_config = config.vqgan_config \n",
        "vqgan_checkpoint = config.vqgan_checkpoint\n",
        "clip_model = config.clip_model\n",
        "clip_dim = CLIP_DIM\n",
        "perceptor = clip.load(clip_model, jit=False)[0].eval().requires_grad_(False).to(device)\n",
        "model = load_vqgan_model(vqgan_config, vqgan_checkpoint).to(device)\n",
        "z_min = model.quantize.embedding.weight.min(dim=0).values[None, :, None, None]\n",
        "z_max = model.quantize.embedding.weight.max(dim=0).values[None, :, None, None]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n",
            "Restored from vqgan_imagenet_f16_16384.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPyPr0s-nZ-h"
      },
      "source": [
        "# Generation of images from text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wTn51eBQXkUX",
        "outputId": "72ded4b0-eb15-4299-b48f-3faf1e09e20b"
      },
      "source": [
        "texts = [\n",
        "    \"berghain queue\"\n",
        "]\n",
        "toks = clip.tokenize(texts, truncate=True)\n",
        "H = perceptor.encode_text(toks.to(device)).float()\n",
        "with torch.no_grad():\n",
        "    z = net(H)\n",
        "    z = clamp_with_grad(z, z_min.min(), z_max.max())\n",
        "    xr = synth(model, z)\n",
        "grid = torchvision.utils.make_grid(xr.cpu(), nrow=len(xr))\n",
        "out_path = f\"{output_path}/gen.jpg\"\n",
        "upscale(out_path)\n",
        "torchvision.transforms.functional.to_pil_image(grid).save(out_path)\n",
        "sz = 256\n",
        "Image(out_path, width=sz*len(texts), height=sz)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Real-ESRGAN'...\n",
            "remote: Enumerating objects: 390, done.\u001b[K\n",
            "remote: Counting objects: 100% (390/390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (247/247), done.\u001b[K\n",
            "remote: Total 390 (delta 208), reused 279 (delta 110), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (390/390), 3.20 MiB | 8.53 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "Collecting basicsr\n",
            "  Downloading basicsr-1.3.4.2.tar.gz (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.18.2)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from basicsr) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from basicsr) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from basicsr) (2.23.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.4.1)\n",
            "Collecting tb-nightly\n",
            "  Downloading tb_nightly-2.7.0a20210919-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from basicsr) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from basicsr) (0.10.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from basicsr) (4.62.2)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->basicsr) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->basicsr) (2021.5.30)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->basicsr) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->basicsr) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->basicsr) (0.12.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->basicsr) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->basicsr) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->basicsr) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly->basicsr) (3.5.0)\n",
            "Building wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.3.4.2-py3-none-any.whl size=182172 sha256=0cd3fa4a7e38e4696e4b39223caee4b3fd069decaee506342ac3404be443559e\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/be/05/7e5677c7d34ee56a2a1e2f05e1ce26a0bf358c1e2fb5ee46c8\n",
            "Successfully built basicsr\n",
            "Installing collected packages: yapf, tb-nightly, addict, basicsr\n",
            "Successfully installed addict-2.4.0 basicsr-1.3.4.2 tb-nightly-2.7.0a20210919 yapf-0.31.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facexlib\n",
            "  Downloading facexlib-0.2.1.0.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from facexlib) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from facexlib) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from facexlib) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from facexlib) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facexlib) (0.10.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from facexlib) (4.62.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy->facexlib) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->filterpy->facexlib) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->facexlib) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->facexlib) (0.34.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->facexlib) (3.7.4.3)\n",
            "Building wheels for collected packages: facexlib, filterpy\n",
            "  Building wheel for facexlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for facexlib: filename=facexlib-0.2.1.0-py3-none-any.whl size=57092 sha256=21f8b37a97f8f92f2ab48872327b1a7721a95d0a861969d17e4aa6fdc5e0da7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/33/8d/70d77abe7eca95c8b0f32f12867234c45c1089db9db7102d03\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=b9b3c897e4f00b739cc49872fa5cf0f611facf7fdc7a6847c16a6b7ef03e260d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n",
            "Successfully built facexlib filterpy\n",
            "Installing collected packages: filterpy, facexlib\n",
            "Successfully installed facexlib-0.2.1.0 filterpy-1.4.5\n",
            "Collecting gfpgan\n",
            "  Downloading gfpgan-0.2.1.tar.gz (35 kB)\n",
            "Requirement already satisfied: facexlib in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.2.1.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gfpgan) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfpgan) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gfpgan) (5.4.1)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.7/dist-packages (from gfpgan) (2.7.0a20210919)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from gfpgan) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.10.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gfpgan) (4.62.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from gfpgan) (0.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->gfpgan) (3.7.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from facexlib->gfpgan) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from facexlib->gfpgan) (7.1.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from facexlib->gfpgan) (0.51.2)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.7/dist-packages (from facexlib->gfpgan) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy->facexlib->gfpgan) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib->gfpgan) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib->gfpgan) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib->gfpgan) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy->facexlib->gfpgan) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->filterpy->facexlib->gfpgan) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->facexlib->gfpgan) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->facexlib->gfpgan) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.40.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->gfpgan) (0.37.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->gfpgan) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->gfpgan) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->gfpgan) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->gfpgan) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly->gfpgan) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly->gfpgan) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly->gfpgan) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly->gfpgan) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->gfpgan) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly->gfpgan) (3.5.0)\n",
            "Building wheels for collected packages: gfpgan\n",
            "  Building wheel for gfpgan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gfpgan: filename=gfpgan-0.2.1-py3-none-any.whl size=35469 sha256=9e30d9162bc255486df8ebf05058b15ac748ae108fc622245b246ecaafbd5323\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/3e/9d/c3334b221f11764db98224dc386fb04d9de005bd7649e37ba0\n",
            "Successfully built gfpgan\n",
            "Installing collected packages: gfpgan\n",
            "Successfully installed gfpgan-0.2.1\n",
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: clize in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.3.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2021.8.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.5.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.19.5)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: taming-transformers-rom1504 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.9.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.10.0+cu102)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip-anytorch->-r requirements.txt (line 1)) (4.62.2)\n",
            "Requirement already satisfied: attrs<22,>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (21.2.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: od in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (1.0)\n",
            "Requirement already satisfied: sigtools>=2.0 in /usr/local/lib/python3.7/dist-packages (from clize->-r requirements.txt (line 2)) (2.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 16)) (3.7.4.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r requirements.txt (line 9)) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r requirements.txt (line 9)) (5.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (0.18.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (0.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 12)) (21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.40.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec->-r requirements.txt (line 4)) (3.7.4.post0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 15)) (4.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning->-r requirements.txt (line 12)) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 15)) (3.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r requirements.txt (line 4)) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 15)) (3.5.0)\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n",
            "--2021-09-19 13:49:45--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/387326890/4f59d7c8-d03f-494e-8595-ae23af075393?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210919%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210919T134946Z&X-Amz-Expires=300&X-Amz-Signature=8d37afbab613385e508e290a9e8ff0c1d0c62081fa891f24a4512b305fce4481&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus_anime_6B.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-09-19 13:49:46--  https://github-releases.githubusercontent.com/387326890/4f59d7c8-d03f-494e-8595-ae23af075393?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210919%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210919T134946Z&X-Amz-Expires=300&X-Amz-Signature=8d37afbab613385e508e290a9e8ff0c1d0c62081fa891f24a4512b305fce4481&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=387326890&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus_anime_6B.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17938799 (17M) [application/octet-stream]\n",
            "Saving to: ‘experiments/pretrained_models/RealESRGAN_x4plus_anime_6B.pth’\n",
            "\n",
            "RealESRGAN_x4plus_a 100%[===================>]  17.11M  29.9MB/s    in 0.6s    \n",
            "\n",
            "2021-09-19 13:49:46 (29.9 MB/s) - ‘experiments/pretrained_models/RealESRGAN_x4plus_anime_6B.pth’ saved [17938799/17938799]\n",
            "\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/gen_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/jpeg": {
              "width": 256,
              "height": 256
            }
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t7M34dMnpIb"
      },
      "source": [
        "# Interpolation video from a set of text prompts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPKtydsWjXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec26129b-f129-40a5-df53-191aa0b849a4"
      },
      "source": [
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "nb_interm = 32 # nb of intermediate images between each successive text prompts\n",
        "bs = 8 # reduce bs (batch size) if memory error\n",
        "texts = [\n",
        "  'fake shaman',\n",
        "  'authentic shaman',\n",
        "  'priest',\n",
        "  'sinner',\n",
        "]\n",
        "toks = clip.tokenize(texts, truncate=True)\n",
        "alpha = torch.linspace(0,1,nb_interm).view(-1,1).to(device)\n",
        "feats = perceptor.encode_text(toks.to(device)).float()\n",
        "\n",
        "H_list = []\n",
        "for i in range(len(texts)-1):\n",
        "  Hi = feats[i:i+1] * (1-alpha) + feats[i+1:i+2] * alpha\n",
        "  H_list.append(Hi)\n",
        "H = torch.cat(H_list)\n",
        "xr_list = []\n",
        "with torch.no_grad():\n",
        "  for i in range(0, len(H), bs):\n",
        "    z = net(H[i:i+bs])\n",
        "    z = clamp_with_grad(z, z_min.min(), z_max.max())\n",
        "    xr = synth(model, z)\n",
        "    xr_list.append(xr.cpu())\n",
        "xr = torch.cat(xr_list)\n",
        "grid = torchvision.utils.make_grid(xr.cpu(), nrow=len(xr))\n",
        "!rm -f *.jpg *.mp4\n",
        "out_path = f\"{output_path}/gen.png\"\n",
        "torchvision.transforms.functional.to_pil_image(grid).save(out_path)\n",
        "upscale(out_path)\n",
        "for i, img in enumerate(xr):\n",
        "  filepath = f\"{output_path}/image_{i:05d}.jpg\"\n",
        "  torchvision.transforms.functional.to_pil_image(img).save(filepath)\n",
        "  upscale(filepath)\n",
        "!ffmpeg -framerate 15 -pattern_type glob -i 'image*.jpg'  -c:v libx264 -r 30 -pix_fmt yuv420p video.mp4 1>&2 2>/dev/null\n",
        "# Show video\n",
        "mp4 = open(\"video.mp4\",'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=256 height=256 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: '/content/output/gen.png' and '/content/output/gen.png' are the same file\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00000_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00001_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00002_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00003_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00004_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00005_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00006_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00007_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00008_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00009_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00010_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00011_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00012_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00013_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00014_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00015_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00016_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00017_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00018_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00019_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00020_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00021_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00022_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00023_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00024_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00025_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00026_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00027_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00028_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00029_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00030_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00031_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00032_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00033_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00034_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00035_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00036_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00037_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00038_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00039_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00040_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00041_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00042_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00043_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00044_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00045_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00046_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00047_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00048_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00049_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00050_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00051_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00052_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00053_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00054_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00055_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00056_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00057_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00058_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00059_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00060_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00061_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00062_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00063_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00064_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00065_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00066_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00067_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00068_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00069_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00070_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00071_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00072_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00073_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00074_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00075_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00076_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00077_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00078_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00079_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00080_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00081_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00082_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00083_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00084_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00085_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00086_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00087_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00088_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00089_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00090_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00091_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00092_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00093_out.jpg': No such file or directory\n",
            "/content\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00094_out.jpg': No such file or directory\n",
            "/content/feed_forward_vqgan_clip\n",
            "[Errno 2] No such file or directory: '/content/Real-ESRGAN'\n",
            "/content/feed_forward_vqgan_clip\n",
            "python3: can't open file 'inference_realesrgan.py': [Errno 2] No such file or directory\n",
            "mv: cannot stat '/content/output/image_00095_out.jpg': No such file or directory\n",
            "/content\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-20e4e48e4355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ffmpeg -framerate 15 -pattern_type glob -i 'image*.jpg'  -c:v libx264 -r 30 -pix_fmt yuv420p video.mp4 1>&2 2>/dev/null\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Show video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:video/mp4;base64,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m HTML(\"\"\"\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'video.mp4'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1LN_4OIQL2d"
      },
      "source": [
        "Image(\"gen.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}