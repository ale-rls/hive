{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DALL·E mini (Text-to-Image)",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118UKH5bWCGa"
      },
      "source": [
        "# DALL·E mini - Inference pipeline\n",
        "\n",
        "*Generate images from a text prompt*\n",
        "\n",
        "<img src=\"https://github.com/borisdayma/dalle-mini/blob/main/img/logo.png?raw=true\" width=\"200\">\n",
        "\n",
        "This notebook illustrates [DALL·E mini](https://github.com/borisdayma/dalle-mini) inference pipeline.\n",
        "\n",
        "For more understanding of the model, refer to [the report](https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "d7rQxnvpZ06N"
      },
      "source": [
        "text_input = 'robot friend by Giuseppe Arcimboldo'  #@param {type: \"string\"}\n",
        "output_path = '/content/output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8LbaonYm3a"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzjAM2GBYpZX"
      },
      "source": [
        "%cd /contnet\n",
        "!pip install -q transformers flax\n",
        "!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git  # VQGAN model in JAX\n",
        "!git clone https://github.com/borisdayma/dalle-mini  # Model files\n",
        "%cd /content/dalle-mini/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phQ9bhjRkgAZ"
      },
      "source": [
        "## Generate encoded images\n",
        "\n",
        "We generate prediction samples from a text prompt using `flax-community/dalle-mini` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyT4tk5EbsdO"
      },
      "source": [
        "from dalle_mini.model import CustomFlaxBartForConditionalGeneration\n",
        "from transformers import BartTokenizer\n",
        "import jax\n",
        "import random\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHv8hKFpcF7R"
      },
      "source": [
        "# make sure we use compatible versions\n",
        "DALLE_REPO = 'flax-community/dalle-mini'\n",
        "DALLE_COMMIT_ID = '4d34126d0df8bc4a692ae933e3b902a1fa8b6114'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k82AaQlGcq0V"
      },
      "source": [
        "# set up tokenizer and model\n",
        "tokenizer = BartTokenizer.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)\n",
        "model = CustomFlaxBartForConditionalGeneration.from_pretrained(DALLE_REPO, revision=DALLE_COMMIT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFSuYbSgIf9"
      },
      "source": [
        "# set a prompt\n",
        "prompt = text_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MRpCVyhZXN"
      },
      "source": [
        "# tokenize the prompt\n",
        "tokenized_prompt = tokenizer(prompt, return_tensors='jax', padding='max_length', truncation=True, max_length=128)\n",
        "tokenized_prompt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y5dqFj7prMQ"
      },
      "source": [
        "Notes:\n",
        "\n",
        "* `0`: BOS, special token representing the beginning of a sequence\n",
        "* `2`: EOS, special token representing the end of a sequence\n",
        "* `1`: special token representing the padding of a sequence when requesting a specific length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmfyDOrm-9hc"
      },
      "source": [
        "n_predictions = 8\n",
        "\n",
        "# create random keys\n",
        "seed = random.randint(0, 2**32-1)\n",
        "key = jax.random.PRNGKey(seed)\n",
        "subkeys = jax.random.split(key, num=n_predictions)\n",
        "subkeys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xcf-BuCivEP"
      },
      "source": [
        "# generate sample predictions\n",
        "encoded_images = [model.generate(**tokenized_prompt, do_sample=True, num_beams=1, prng_key=subkey) for subkey in tqdm(subkeys)]\n",
        "encoded_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3m2lxNOrQWG"
      },
      "source": [
        "The first token (`16384`) is a special token representing the start of a sequence in the decoder (not part of the image codebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIOjC-KEq5NT"
      },
      "source": [
        "# remove first token (BOS)\n",
        "encoded_images = [img.sequences[..., 1:] for img in encoded_images]\n",
        "encoded_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "037WuNLXsCoq"
      },
      "source": [
        "The generated images are now represented by 256 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5KQfjilqvbt"
      },
      "source": [
        "encoded_images[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDiVxh1wfrJ1"
      },
      "source": [
        "## Decode images\n",
        "\n",
        "The generated images need to be decoded with `flax-community/vqgan_f16_16384`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAmCIun8ftiY"
      },
      "source": [
        "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzJyQhk9fvT2"
      },
      "source": [
        "# make sure we use compatible versions\n",
        "VQGAN_REPO = 'flax-community/vqgan_f16_16384'\n",
        "VQGAN_COMMIT_ID = '90cc46addd2dd8f5be21586a9a23e1b95aa506a9'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9LrXhvJcx6o"
      },
      "source": [
        "# set up VQGAN\n",
        "vqgan = VQModel.from_pretrained(VQGAN_REPO, revision=VQGAN_COMMIT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hXb-F2bbMxK"
      },
      "source": [
        "# decode images\n",
        "decoded_images = [vqgan.decode_code(encoded_image) for encoded_image in tqdm(encoded_images)]\n",
        "decoded_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqQM16K9L7HA"
      },
      "source": [
        "# normalize images\n",
        "clipped_images = [img.squeeze().clip(0., 1.) for img in decoded_images]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isW9m1B9CH1V"
      },
      "source": [
        "# convert to image\n",
        "images = [Image.fromarray(np.asarray(img * 255, dtype=np.uint8)) for img in clipped_images]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPISO6sE-cI4"
      },
      "source": [
        "!mkdir -p $output_path\n",
        "# display an image\n",
        "for idx in range(len(images)):\n",
        "    #display(images[idx])\n",
        "    idx_str = '{:05}'.format(idx)\n",
        "    save_path = f\"{output_path}/image_{idx}.png\"\n",
        "    images[idx].save(save_path)\n",
        "    print(\"saved image to \", save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew0cQYCGdKQU"
      },
      "source": [
        "!sleep 10"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}